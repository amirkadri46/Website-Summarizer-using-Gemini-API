{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7070cd4-b326-496d-94e7-9bbb99113839",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa62a3-4bef-47e1-bf0b-58e7470c566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini-compatible imports\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import google.generativeai as genai "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37cae6-e6ff-4592-828e-96d54ab2d50f",
   "metadata": {},
   "source": [
    "# Connecting to Gemini\n",
    "\n",
    "The next cell is where we load in the environment variables in your `.env` file and connect to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b8c27-b2ff-4e22-b37e-bd9f2ed555f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Gemini\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('GEMINI_API_KEY')  # Changed environment variable name\n",
    "\n",
    "# Check the key\n",
    "if not api_key:\n",
    "    print(\"No Gemini API key found! Please:\")\n",
    "    print(\"1. Create a .env file in this folder\")\n",
    "    print(\"2. Add: GEMINI_API_KEY=your_actual_api_key_here\")\n",
    "    print(\"3. Get your API key from: https://aistudio.google.com/app/apikey\")\n",
    "elif not api_key.startswith(\"AIza\"):\n",
    "    print(\"Gemini API key found, but it doesn't start with 'AIza'\")\n",
    "    print(\"This suggests an invalid key format - get a new one from Google AI Studio\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"Key detected, but it has leading/trailing whitespace!\")\n",
    "    print(\"Remove spaces/tabs around the key in your .env file\")\n",
    "else:\n",
    "    print(\"Gemini API key validated successfully! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a2ad1-028c-4f36-b912-c41ba4aed963",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e4bdcd-8250-4fa2-9ab3-d99a605323ae",
   "metadata": {},
   "source": [
    "# Check for tha available model in Gemini and choose form that to run you model\n",
    "\n",
    "EG: Name: models/gemini-1.5-pro-latest\n",
    "Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d695e7-2297-4f98-9ad7-4a1e6c4c7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(f\"Name: {m.name}\")\n",
    "        print(f\"Description: {m.description}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de077630-882a-4fa4-a262-e5712b90695b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e220db-d5c3-4d68-8bbb-15f250b948ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550b429-5924-45a8-90e2-4acabfd74399",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-pro-latest')  # New"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f379c1f-4500-49f6-acb1-22abe2fa5246",
   "metadata": {},
   "source": [
    "# Generate AI Response with Token Limit  \n",
    "This code uses an AI model to generate a response to a prompt, limiting the output to **1,000 tokens** \n",
    "(shorter than the default 2048). \n",
    "Replace `\"Your prompt here\"` with your input text. Useful for controlling response length or API costs.  \n",
    "ps:( you can also use default but i had set it to 1000 token for convenience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a5a6ef-056f-414f-83e4-04156e905fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Set max output tokens\n",
    "response = model.generate_content(\n",
    "    \"Your prompt here\",\n",
    "    generation_config=genai.types.GenerationConfig(\n",
    "        max_output_tokens=1000  # Default is 2048\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513ad8d5-7ea2-481e-970d-1ff6ab8c420f",
   "metadata": {},
   "source": [
    "# Basic Gemini Model Connectivity Test  \n",
    "This code verifies connectivity to Google's Gemini AI model. It:  \n",
    "1. Loads the API key securely from a `.env` file.  \n",
    "2. Initializes the `gemini-1.5-pro-latest` model.  \n",
    "3. Sends a test prompt and prints a **5-word confirmation** to validate functionality.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62bf91-edda-41ef-8854-fbf410aa9887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full test code\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "response = model.generate_content(\"Hello! Can you confirm you're working? Answer in 5 words.\")\n",
    "print(response.text)  # Should return short confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4db528-556c-4338-b565-c5f064c7f468",
   "metadata": {},
   "source": [
    "# Let's make a quick call to a Frontier model to get started, as a preview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb77b0-9453-4ee8-a167-8f6ef44abb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment and configure\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "\n",
    "# Initialize model\n",
    "model = genai.GenerativeModel('gemini-1.5-pro-latest')  # Use your verified model name\n",
    "\n",
    "# Generate response\n",
    "message = \"Hello, Gemini! This is my first ever message to you! Hi!\"\n",
    "response = model.generate_content(message)\n",
    "\n",
    "# Handle response\n",
    "if response.text:\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(\"Response blocked. Safety feedback:\", response.prompt_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6e885-8717-49fb-9859-abb940da6bac",
   "metadata": {},
   "source": [
    "# Web Scraping & Content Cleaning  \n",
    "This code scrapes a webpage and extracts clean text content:  \n",
    "1. Uses a `User-Agent` header to mimic a browser.  \n",
    "2. Removes scripts, styles, and other non-text elements.  \n",
    "3. Stores the page title and cleaned body text in a `Website` object.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d1ec0-1501-4cdd-b657-0233c38c1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Creates a Website object with cleaned text content from the URL\n",
    "        - Scrapes page using requests/BeautifulSoup\n",
    "        - Removes unnecessary elements (scripts, styles, etc.)\n",
    "        - Stores cleaned text content\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        \n",
    "        # 1. Fetch webpage\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # 2. Parse HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # 3. Extract and clean content\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for element in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            element.decompose()  # Remove unwanted elements\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f72e46-d237-4c31-ba03-59d9798c37da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8bd71-4088-4629-9ecb-ee349129cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "google = Website(\"https://google.com\")  # Initializes using your Website class\n",
    "\n",
    "# Print results (no changes needed here)\n",
    "print(\"Page Title:\", ed.title)\n",
    "print(\"\\nCleaned Page Content:\")\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49adf69-4ca5-4de9-aff1-80eb27d8ac98",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT4o have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e659c938-6f70-4062-83e3-4ac02620767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4bb74c-f91f-4920-9dfc-c9b768dbc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25e89d-90a5-4fa5-be3d-0618fd2f5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_prompt_for(google))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d307f-a836-471f-ad95-a02b6b9a2eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f72a5-8e7a-4ed5-a6fd-168d01b5556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7392965-d19f-402a-9c55-6829b55b4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant... Respond in markdown.\"\n",
    "user_prompt = \"Summarize this website...\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "# Gemini version\n",
    "full_prompt = f\"\"\"<SYSTEM_ROLE>\n",
    "{system_prompt}\n",
    "</SYSTEM_ROLE>\n",
    "\n",
    "<USER_REQUEST>\n",
    "{user_prompt}\n",
    "</USER_REQUEST>\"\"\"\n",
    "\n",
    "response = genai.GenerativeModel('gemini-1.5-pro-latest').generate_content(full_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4c098-cc6a-498d-8d78-aba78a72e9b4",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for GEMINI, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091db9c-809b-422f-85eb-94238d40a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    # Gemini uses single-string prompts instead of role-based messages\n",
    "    return f\"{system_prompt}\\n\\n{user_prompt_for(website)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3c9b8-e45d-4e1f-956b-f6b31df5b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(google)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d3654-33ec-4d3d-be7d-24bbef34c0e0",
   "metadata": {},
   "source": [
    "## Time to bring it together - the API for Gemini is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa0b05-a452-4d2f-8244-9129395c01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the Gemini API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = genai.GenerativeModel('gemini-1.5-pro-latest').generate_content(\n",
    "        messages_for(website)  # Already returns combined prompt string\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89949e-9b31-4c3d-9547-3022d0d394a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08c04a-7325-4696-b238-6f21fc4eea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cf036-7a64-49f3-ba0b-ef59382fa5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://www.blackbox.ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f6e3d-a036-4c2f-a4da-b50cec5b997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd876bb2-412c-449a-9f25-a6fc7f2c53bb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This Website Summarizer demonstrates how to combine web scraping, content cleaning, and Gemini's AI capabilities to create focused website summarizer model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
